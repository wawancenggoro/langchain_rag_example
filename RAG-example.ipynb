{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abe1f5b6",
   "metadata": {},
   "source": [
    "# Add reference documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99cef9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('var.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "618ace1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"cloudeka.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(file_path=pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=30, separator=\"\\n\")\n",
    "split_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"baai/bge-multilingual-gemma2\",\n",
    "    base_url=\"https://dekallm.cloudeka.ai/\"\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.from_documents(split_documents, embeddings)\n",
    "vectorstore.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3133611",
   "metadata": {},
   "source": [
    "### Test query from vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdb2d24",
   "metadata": {},
   "source": [
    "Here, reference documents that are relevant to the user prompt are retrieved from the vector database. As we can see, the retrieved documents here are just a substring of the whole content in the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df7138b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Service Portal Cloudeka\n",
      "Cloudeka is a Cloud Computing platform that provides various cloud services\n",
      "including computing, storage, networking, and more. Cloudeka is supported\n",
      "by self-service through the dashboard service portal with features to\n",
      "configure, create projects, check billing, view and create rules in the\n",
      "organization. users can choose carefully from these services to develop new\n",
      "applications, or run existing applications on Cloudeka. Users can choose\n",
      "carefully the services to develop new applications, or to run existing\n",
      "applications on Cloudeka. There are two types of projects: Prepaid and \n",
      "Postpaid.\n",
      "1.Prepaid\n",
      "For the Prepaid type, it is used for personal needs that use personal email\n",
      "addresses and can only have one project so that the subscription period is\n",
      "relatively short without a letter of contract. For payment methods using \n",
      "Virtual Account, LinkAja, OVO, Credit Card.\n",
      "At the beginning of registration, the deposit must be at least IDR 50,000.00.\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "retrieved_documents = retriever.invoke(\"What is cloudeka?\")\n",
    "print(retrieved_documents[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d84db75",
   "metadata": {},
   "source": [
    "# Run RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ad75294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('var.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2584f14",
   "metadata": {},
   "source": [
    "### Initialize embedding model and chat model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cac0252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"baai/bge-multilingual-gemma2\",\n",
    "    base_url=\"https://dekallm.cloudeka.ai/\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"qwen/qwen25-72b-instruct\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    base_url=\"https://dekallm.cloudeka.ai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8074eb",
   "metadata": {},
   "source": [
    "### Load the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cb6a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.load_local(\n",
    "    \"faiss_index\", embeddings, allow_dangerous_deserialization=True\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3511e302",
   "metadata": {},
   "source": [
    "### Create prompt template and how to insert context to the template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2dcf9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"  \n",
    "    Given this context: {context}\n",
    "    Answer this question = {question}\n",
    "    You need to answer the question in the sentence as same as in the context. \n",
    "    If the answer is not in the context, answer \"I cannot answer\"\n",
    "    \"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0d532d",
   "metadata": {},
   "source": [
    "# Run RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a5aa57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloudeka is a Cloud Computing platform that provides various cloud services including computing, storage, networking, and more. Cloudeka is supported by self-service through the dashboard service portal with features to configure, create projects, check billing, view and create rules in the organization. Users can choose carefully from these services to develop new applications, or run existing applications on Cloudeka.\n"
     ]
    }
   ],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "prompt = \"What is Cloudeka?\"\n",
    "response = rag_chain.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e5ba2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
